---
title: "vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This notebook demonstrates the use of the package "Vivaldi" to analyze viral single nucleotide variants from next generation sequencing data (e.g. Illumina). This vignette takes variant data in the form of VCF files generated using the MAD2 pipeline (https://github.com/gencorefacility/MAD2) and the variant callers timo and iVar. It performs analyses to summarize genetic diversity. 

# Table of Contents
* Load package
* Step 1: Set path for variant data and metadata
* Step 2: Loading data and arranging
    + arrange_data()
    + filter_variants()
    + prepare_annotations()
    + add_metadata()
    + merge_replicates()
* Step 3: Calculations & Plots
    + 

# Load Vivaldi pacakge
```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

The vivaldi package is available on Cran and is loaded as follows: 
```{r setup}
library(vivaldi)
library(kableExtra)
```

## Vignette data set
The data used in this vignette are simulated influenza genomes with known mutations generated at random frequencies. (More description here)

# Step 1: Set path for variant data and metadata

The data used in this vignette is included with the package. For running their own data, users should set give the path to those files here. 
```{r}
# Set variables that we will use
vardir = system.file("extdata", "vcfs", package="vivaldi") 
```

Metadata used for the calculations includes a .csv file containing the lengths of each of the viral segments. For non-segmented viruses, simply report the whole length of the genome. Useres should also set a variable with the total length of their viral genome. 
```{r}
seg_sizes = system.file("extdata", "SegmentSize.csv", package="vivaldi")
sizes = read.csv(file=seg_sizes,header=T,sep=",",na.strings = c(''))
genome_size = 13133
```

If relevant, the user should also supply a .csv file containing information about sequencing replicates containing 3 columns: the filename of both replicates, which replicate the sample represents, and the new sample name for the merged replicates. 
```{r}
rep_info = system.file("extdata", "reps.csv", package="vivaldi")
replicates = read.csv(file = rep_info, header = T, sep = ",", na.strings = c(""))
```

If working with a segmented genome, users should also give a string containing the segments in the desired order for plots. 
```{r}
SEGMENTS = c("H1N1_PB2","H1N1_PB1","H1N1_PA","H1N1_HA","H1N1_NP","H1N1_NA","H1N1_MP","H1N1_NS")
```

# Step 2: Loading in data and arranging 

## Load VCF files into a dataframe
The first step of the work flow is to load the VCF files into R and extract the important information. The output of this function is a tidy dataframe that contains the sample name, pulled from the VCF file name, and information about the reference and alternative allele. If the VCF has not previously been annotated by SNPeff (recommended), the user should specify annotated = "no" for either function. 
```{r, include = FALSE}
VCF_DF = arrange_gt_data(vardir, ref = system.file("extdata", "H1N1.fa", package="vivaldi"), annotated = 'yes')
#todo: merge three arrange_* functions into a single function

kable(head(VCF_DF))
dim(VCF_DF)
```
The VCF_DF dataframe now contains all variants from all of the files. Columns contain:
* sample: name of the sample the variant was found in (pulled from VCF file name)
* CHROM: segment the variant was found on
* POS: nucleotide position of the variant
* REF: nucleotide found at this position in the reference genome provided ("ref = ")
* ALT: nucleotide found at this position in the sample 
* ANN: annotation information from SNPeff, not yet formatted 
* gt_DP: total number of reads (i.e. depth) that cover this position
* REF_COUNT: number of reads that include the REF nucleotide
* ALT_COUNT: number of reads that include the ALT nucleotide
* REF_FREQ: frequency of the reference nucleotide, calculated as the REF_COUNT divided by the gt_DP
* ALT_FREQ: frequency of the alternate nucleotide, calculated as the ALT_COUNT divided by the gt_DP
* ALT_TYPE: categorization of the alternate nucleotide. If found at frequencies > 50%, it is labelled a major; if found at frequencies < 50%, it is labelled a minor.
* major: major nucleotide
* minor: minor nucleotide
* majorfreq: frequency of the major nucleotide
* minorfreq: frequency of the minor nucleotide
* majorcount: number of reads containing the major nucleotide
* minorcount: number of reads containing the minor nucleotide

## Merge Replicates
Sequencing in replicate allow us to keep only those variants found in both runs, as any sequencing or PCR errors are extremely unlikely to be found in independent experiments. For this function, the user must provide the variant dataframe and the loaded replicates dataframe. In addition, whatever name the user provides for the replicates (ex. "Rep1", "r1", "rep1", etc) must be provided in quotes, as well as a list of columns that should be used to merge the two dataframes. This should contain any columns that are expected to be identical between the two replicates, such as the segment and nucleotide position of the variant as well as any SNPeff annotation information. It should not contain replicate-specific information such as the allele frequency of the variant. We calculate the average allele frequency for both the ALT and REF allele, as well as the weighted average, which considers the number of reads for each replicate as well. We expect these to be generally similar, unless one of the replicates has significantly higher coverage per sample than the other.
```{r}
cols = c("sample","CHROM","POS","REF","ALT","ANN","ALT_TYPE","major","minor")

DF_reps = merge_replicates(VCF_DF,replicates,"rep1","rep2",cols)

# if you want to have your segments in certain order must reorder before plotting:
DF_reps$CHROM = factor(DF_reps$CHROM, levels = SEGMENTS)
```

## Filter out variants based on coverage and/or frequency cutoffs
This function filters the variants by frequency or coverage of the ALT allele. Based on (our paper), we recommend 1% allele frequency and no coverage cutoff for sequencing data with replicates. For sequencing data without replicates, a much more stringent filtering step is recommended to ensure confidence in the variants called. We suggest a 3% allele frequency and 200X coverage for data without replicates. 
```{r}
# Use default coverage (300) and frequency (0.02) cutoffs 
# or set custom values
cov_cutoff = 400
freq_cutoff = 0.02
DF_filt = filter_variants(VCF_DF)
#DF_filt = filter_variants(VCF_DF, coverage_cutoff=cov_cutoff, frequency_cutoff=freq_cutoff)

kable(head(DF_filt))
dim(DF_filt)
```

## Format SNPeff information
This function takes the one large annotation column containing annotation information from SNPeff and separates them out into individual columns with one attribute each.
```{r}
DF_filt = prepare_annotations(DF_filt)

kable(head(DF_filt))
dim(DF_filt)
```

## Add metadata (segment and genome size)
Here, we add in information about the sizes of the segments, which will allow us to do downstream calculations like tstv, dNdS, and others. The user must provide both the variant dataframe and the loaded metadata dataframe, as well as the names of the columns to merge by in both. 
```{r}
DF_filt = add_metadata(DF_filt, sizes, c('CHROM'), c('segment'))

kable(head(DF_filt))
dim(DF_filt)
```


# Step 2: Calculations

## Calculate Shannon entropy
Shannon entropy is a commonly used metric to describe the amount of genetic diversity in sequencing data. It is calculated by considering the frequency of the ALT and REF allele at every position and then summing those values over either a segment or over the entire genome. These values can then be normalized by kb in order to compare across different segments or samples. As a result, this function outputs a dataframe with five new columns reflecting these different calculations. The user must provide the variant dataframe and the length of the genome they are working with. 
```{r}
DF_filt_reps = shannon_entropy(DF_filt_reps,genome_size)

kable(head(DF_filt_reps))
dim(DF_filt_reps)
```

## Count number of SNVs
The function tally_it() allows the user to count the number of variants over a given set of variables. These variables should be provided as a list and then passed into the function in addition to the name, in quotes, for the new column containing the number of variants. For example, to get the sum of variants on every segment, the user should construct as list containing the name of the sample column and the name of the segment column and pass that list into the function. 
```{r}
# Across segments:
group_list_seg = c('sample','CHROM', "SegmentSize")
seg_count = tally_it(DF_filt_reps, group_list_seg, "snv_count")

kable(head(seg_count))


# Across genome:
group_list_gen = c('sample')
gen_count = tally_it(DF_filt_reps, group_list_gen, "snv_count")

kable(head(gen_count))
```

## Calculate Transitions/Transversions Ratio 
The transition/transversion rate is commonly used to test for a bias in nucleotide conversions. Transitions are expected to be more common. Here, the user must provide the variant dataframe and the length of the genome, as this ratio will be calculated by segment and over the whole genome. 
```{r}
DF_tstv = tstv_ratio(DF_filt_reps,genome_size)
kable(head(DF_tstv))
```

# Step 3: Generate plots

## Plot location of SNVs across segments
This function takes the variant dataframe and generates a large, interactive plot of all of the variants. The plot will be faceted by each segment for each individual sample. The user can scroll over each point in the plot to get information about that variant, including the nucleotide change and the position on the segment.
```{r}
#library(plotly)
snv_location(DF_filt_reps)
```

## Plot number of SNVs per sample and per segment
The snv_genome() function will take the variant dataframe and generate a plot of the number of variants per genome and colors them by their SNPeff annotation, while the snv_segment() function will generate the same plot but faceted by segment. 
```{r}
snv_genome(DF_filt_reps)
snv_segment(DF_filt_reps)
```

## Plot TsTv
This function will take the variant dataframe and generates 4 plots: the Ts/Tv ratio across the genome, the ratio across each segment, and both plots normalized by kb. 
```{r}
tstv_plot(DF_tstv)
```

## Plot shannon entropy per sample and per segment
This function takes the variant dataframe and generates three plots: the shannon entropy value for every variant, the sum of these values over each segment, and the sum over the entire genome. A higher Shannon entropy value indicates more diversity. 
```{r}
# makes 3 plots
plot_shannon(DF_filt_reps)
```

## Determine if variants are shared among samples
This function takes the variant dataframe and generates a plot that annotates the variants based on the number of times it appears in independent samples. The darker the color of the point, the more samples that variant is found in. Depending on the context of the user's experimental design, a variant that is found in many samples could be an indication of convergent evolution and would potentially be a good starting point for deeper investigation. 
```{r}
shared_snv_plot(DF_filt_reps)
```

## Print dataframe of variants shared among samples for further analysis
This function takes the variant dataframe and creates a new table, listing the variants in descending order of how many samples they are found in. This function is meant to simplify further investigation of visual patterns in the previous plot. 
```{r}
shared_snv_table(DF_filt_reps)
```

## Isolate variant of interest and plot AF at that position in all samples
This function allows users to focus on a single variant of interest and track the allele frequency of the ALT and the REF allele in all samples it is found in. To run, the user must provide the variant dataframe and the segment name and nucleotide position, in quotes, of the variant they are interested in. This can be run for any variant found in the sequencing data. 
```{r}
# provide the df, segment, and variant position
position_allele_freq(DF_filt_reps,"H1N1_HA", "1007")
```

## Calculate dNdS ratio and plot per sample per segment
The dN/dS ratio is commonly used to test for a bias in amino acid conversions. dN counts the number of nonsynonymous mutations, or nucleotide changes that result in an amino acid change in the resulting protein product. dS counts the number of synonymous mutations, which don't result in an amino acid change and are not expected to be under strong selection. Under neutral evolution, the dN/dS is expected to be approx. equal to 1, while a ratio > 1 indicates an enrichment of nonsynonymous changes, a hallmark of positive selection, and a ratio < 1 indicates a depletion of nonsynonymous changes, a hallmark of negative or purifying selection. The user must provide the variant dataframe that contains information about the amino acid changes for all nucleotide variants, otherwise this metric will not accurately reflect the true value.  
```{r}
##dNdS_segment ## SAYS NEEDS dataframe - must be for amino-acid specific calculations, cannot be the same as the dataframe used for SNP calculations
```

## Plot distribution of all minor variant frequencies
This function takes the variant dataframe and generates a plot showing the distribution of the the minor variants (appearing in less than 50% of the reads for any sample). For many viruses, we expect the distribution to be skewed to very low frequency variants (< 10%). 
```{r}
af_distribution(DF_filt_reps)
```
